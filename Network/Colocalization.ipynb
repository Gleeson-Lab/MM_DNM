{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9be669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327daf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gene_tolist(file):\n",
    "    l =[]\n",
    "    f = open(file, 'r')\n",
    "    for line in f:\n",
    "        if 'locus' in line:\n",
    "            l_header = line.strip().split('\\t')\n",
    "        else:\n",
    "            s = line.strip().split('\\t')\n",
    "            dic = dict(zip(l_header, s))\n",
    "            gene = dic['SYMBOL']\n",
    "            l.append(gene)\n",
    "    return (l)\n",
    "            \n",
    "l_NTD=gene_tolist(\"NTD_DamMC2_woINVALID.den_input\") #DamMC2 without six invalidated calls\n",
    "print (len(l_NTD))   \n",
    "l_SSC=gene_tolist(\"SSC_DamMC2.den_input\")\n",
    "print (len(l_SSC)) \n",
    "l_random = []\n",
    "f_random = open(\"9606.protein.info.v12.0.txt\", 'r') #STRING database\n",
    "dic_convert = {}\n",
    "for line in f_random:\n",
    "    if '#' not in line:\n",
    "        l_random.append(line.split('\\t')[1])\n",
    "        dic_convert[line.split('\\t')[0]] = line.split('\\t')[1]\n",
    "print (len(l_random))\n",
    "l_random2 = list(set(l_random) - set(l_NTD)-set(l_SSC))\n",
    "print (len(l_random2)) #ALl genes that doesn't contain NTD and SSC genes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df0216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract NTD and SSC interaction from the random set \n",
    "f_int_random = open(\"9606.protein.links.v12.0.txt\", 'r')\n",
    "out_int_NTD_from_random = open(\"9606.protein.links.v12.0.converted_NTD.txt\", 'w')\n",
    "out_int_SSC_from_random = open(\"9606.protein.links.v12.0.converted_SSC.txt\", 'w')\n",
    "for line in f_int_random:\n",
    "    if 'protein' in line:\n",
    "        out_int_NTD_from_random.write('#' + line )\n",
    "        out_int_SSC_from_random.write('#' + line )\n",
    "        pass\n",
    "    else:\n",
    "        s = line.split()\n",
    "        node1 = s[0]\n",
    "        node2 = s[1]\n",
    "        s[0]= dic_convert[node1]\n",
    "        s[1] = dic_convert[node2]\n",
    "        if s[0] in l_NTD and s[1] in l_NTD:\n",
    "            #print (s)\n",
    "            out_int_NTD_from_random.write('\\t'.join(s) + '\\n')\n",
    "        if s[0] in l_SSC and s[1] in l_SSC:\n",
    "            out_int_SSC_from_random.write('\\t'.join(s) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91d7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go for the network colocalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "size_subset = int(round(len(l_SSC)*0.8,0))\n",
    "print (size_subset)\n",
    "l_sub_NTD = []\n",
    "l_sub_random = []\n",
    "n_iter = 100000\n",
    "for i in range(n_iter):\n",
    "    l_sub_NTD.append(random.sample(l_NTD, k=size_subset))\n",
    "    #l_sub_SSC.append(random.sample(l_SSC, k=size_subset))\n",
    "    l_sub_random.append(random.sample(l_random, k=size_subset))\n",
    "\n",
    "\n",
    "print (len(l_sub_random))\n",
    "\n",
    "f_int_NTD = open(\"9606.protein.links.v12.0.converted_NTD.txt\", 'r')\n",
    "dic_edges_NTD ={}\n",
    "l_cnt_NTD = []\n",
    "l_cnt_random = []\n",
    "for line in f_int_NTD:\n",
    "    if '#' in line:\n",
    "        l_header = line.strip().split()\n",
    "        print (l_header)\n",
    "    else:\n",
    "        dic=dict(zip(l_header, line.strip().split('\\t')))\n",
    "        node1 = dic['#protein1']\n",
    "        node2 = dic['protein2']\n",
    "        if node1 not in dic_edges_NTD:\n",
    "            dic_edges_NTD[node1] =  [node2]\n",
    "        else:\n",
    "            dic_edges_NTD[node1].append(node2)\n",
    "        \n",
    "\n",
    "print (len(dic_edges_NTD))\n",
    "\n",
    "l_edge_weight_ntd_total = []\n",
    "\n",
    "\n",
    "for subnet in l_sub_NTD:\n",
    "    dic_edge_weight_ntd = {}\n",
    "    cnt = 0\n",
    "    each_gene_subnet = subnet #e\n",
    "    for gene in each_gene_subnet:\n",
    "        if gene in dic_edges_NTD:\n",
    "            l_counter = dic_edges_NTD[gene] #counters\n",
    "            for counter in l_counter:\n",
    "                if counter in each_gene_subnet:\n",
    "                #print (gene, counter)\n",
    "                    cnt +=1 \n",
    "                    if gene not in dic_edge_weight_ntd:\n",
    "                        dic_edge_weight_ntd[gene] = [counter]\n",
    "                    elif gene in dic_edge_weight_ntd:\n",
    "                        dic_edge_weight_ntd[gene].append(counter)\n",
    "                    if counter not in dic_edge_weight_ntd:\n",
    "                        dic_edge_weight_ntd[counter] = [gene]\n",
    "                    else:\n",
    "                        dic_edge_weight_ntd[counter].append(gene)\n",
    "    \n",
    "    l_cnt_NTD.append(cnt)\n",
    "    l_edge_weight_ntd_total.append(dic_edge_weight_ntd)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = open(\"per_node_ntd_100k.txt\", 'w')\n",
    "out.write(\"cohort\\tTurn\\tedge_per_node\\tedge_cnt\\n\")\n",
    "dic_per_node = {}\n",
    "cnt = 0\n",
    "for ite in l_edge_weight_ntd_total:\n",
    "    dic_per_node[cnt] = {}\n",
    "    each_dic = ite\n",
    "    \n",
    "    for gene in each_dic:\n",
    "        nondup = list(set(each_dic[gene]))\n",
    "        #print (gene,nondup)\n",
    "        per_node = len(nondup)\n",
    "        if per_node not in dic_per_node[cnt]:\n",
    "            dic_per_node[cnt][per_node] = 1\n",
    "        else:\n",
    "            dic_per_node[cnt][per_node] +=1\n",
    "    cnt +=1\n",
    "        \n",
    "for turn in dic_per_node:\n",
    "    #print (dic_per_node[turn])\n",
    "    cnt_each_turn = 0\n",
    "    for pernode in dic_per_node[turn]:\n",
    "        #print (\"YES\")\n",
    "        cnt_each_turn += dic_per_node[turn][pernode]\n",
    "        out.write('MM\\t' + str(turn) + '\\t' + str(pernode) + '\\t' + str(dic_per_node[turn][pernode]) + '\\n')\n",
    "    Noconnection = size_subset -cnt_each_turn\n",
    "    out.write('MM\\t' + str(turn) + '\\t' + str(0) + '\\t' + str(Noconnection) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc543c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "size_subset = int(round(len(l_SSC)*0.8,0))\n",
    "l_sub_SSC = []\n",
    "l_sub_random = []\n",
    "n_iter = 100000\n",
    "for i in range(n_iter):\n",
    "    #l_sub_NTD.append(random.sample(l_NTD, k=size_subset))\n",
    "    l_sub_SSC.append(random.sample(l_SSC, k=size_subset))\n",
    "    l_sub_random.append(random.sample(l_random, k=size_subset))\n",
    "\n",
    "\n",
    "#print (l_sub_random)\n",
    "\n",
    "f_int_SSC = open(\"9606.protein.links.v12.0.converted_SSC.txt\", 'r')\n",
    "dic_edges_SSC ={}\n",
    "l_cnt_SSC = []\n",
    "l_cnt_random = []\n",
    "for line in f_int_SSC:\n",
    "    if 'protein' in line:\n",
    "        l_header = line.strip().split()\n",
    "        print (l_header)\n",
    "    else:\n",
    "        dic=dict(zip(l_header, line.strip().split('\\t')))\n",
    "        node1 = dic['#protein1']\n",
    "        node2 = dic['protein2']\n",
    "        if node1 not in dic_edges_SSC:\n",
    "            dic_edges_SSC[node1] =  [node2]\n",
    "        else:\n",
    "            dic_edges_SSC[node1].append(node2)\n",
    "        \n",
    "#print (dic_edges_NTD)\n",
    "#print (len(dic_edges_SSC))\n",
    "#cnt0 =0\n",
    "l_edge_weight_ssc_total = []\n",
    "\n",
    "for subnet in l_sub_SSC:\n",
    "    dic_edge_weight_ssc = {}\n",
    "    cnt = 0\n",
    "    each_gene_subnet = subnet #e\n",
    "    for gene in each_gene_subnet:\n",
    "        if gene in dic_edges_SSC:\n",
    "            l_counter = dic_edges_SSC[gene] #counters\n",
    "            for counter in l_counter:\n",
    "                if counter in each_gene_subnet:\n",
    "                #print (gene, counter)\n",
    "                    cnt +=1\n",
    "                    if gene not in dic_edge_weight_ssc:\n",
    "                        dic_edge_weight_ssc[gene] = [counter]\n",
    "                    elif gene in dic_edge_weight_ssc:\n",
    "                        dic_edge_weight_ssc[gene].append(counter)\n",
    "                    if counter not in dic_edge_weight_ssc:\n",
    "                        dic_edge_weight_ssc[counter] = [gene]\n",
    "                    else:\n",
    "                        dic_edge_weight_ssc[counter].append(gene)\n",
    "    l_edge_weight_ssc_total.append(dic_edge_weight_ssc)\n",
    "    l_cnt_SSC.append(cnt)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff267821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (l_edge_weight_ssc_total)\n",
    "dic_per_node = {}\n",
    "cnt = 0\n",
    "for ite in l_edge_weight_ssc_total:\n",
    "    dic_per_node[cnt] = {}\n",
    "    each_dic = ite\n",
    "    \n",
    "    for gene in each_dic:\n",
    "        nondup = list(set(each_dic[gene]))\n",
    "       # print (gene,nondup)\n",
    "        per_node = len(nondup)\n",
    "        if per_node not in dic_per_node[cnt]:\n",
    "            dic_per_node[cnt][per_node] = 1\n",
    "        else:\n",
    "            dic_per_node[cnt][per_node] +=1\n",
    "    cnt +=1\n",
    "        \n",
    "for turn in dic_per_node:\n",
    "    #print (dic_per_node[turn])\n",
    "    cnt_each_turn = 0\n",
    "    for pernode in dic_per_node[turn]:\n",
    "        #print (\"YES\")\n",
    "        cnt_each_turn += dic_per_node[turn][pernode]\n",
    "        out.write('Control\\t' + str(turn) + '\\t' + str(pernode) + '\\t' + str(dic_per_node[turn][pernode]) + '\\n')\n",
    "    Noconnection = size_subset -cnt_each_turn\n",
    "    out.write('Control\\t' + str(turn) + '\\t' + str(0) + '\\t' + str(Noconnection) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7d8a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open(\"/projects/ps-gleesonlab8/User/hiyoothere/NTD/11.Network_analysis/231125/input/ntd_coloc_100k_iter_0.8contsize.txt\", 'w')\n",
    "out.write(\"cohort\\tconnection\\n\")\n",
    "\n",
    "for i in l_cnt_NTD:\n",
    "    out.write(\"MM\\t\" + str(i) + '\\n')\n",
    "for i in l_cnt_SSC:\n",
    "    out.write(\"Control\\t\" + str(i) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd4f568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e414f0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
